<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>


# python操作

## 创建一维数组的方式
- np.array(列表、元组、镶嵌列表)
- np.arange() 通过指定开始值、终值和步长来创建一维数组，注意数组不包括终值
- np.linspace() 开始值、终值和元素个数，默认包含终值，endpoin也可指定
- zeros()、ones()、empty()、zeros_like()、ones_like()、empty_like()


使用数组的reshape方法，可以创建一个改变了尺寸的新数组，原数组的shape保持不变。共享数据存储内存区域，因此修改其中任意一个数组的元素都会同时修改另外一个数组。

数组取值：
a[3:5] 含下界不含上界
步长为负数时，开始下标必须大于结束下标

和Python的列表序列不同，通过下标范围获取的新的数组是原始数组的一个视图。它与原始数组共享同一块数据空间

当使用整数序列对数组元素进行存取时，将使用整数序列中的每个元素作为下标，整数序列可以是列表或者数组。使用整数序列作为下标获得的数组不和原始数组共享数据空间。 \

```python
 x[[3, 3, 1, 8]] # 获取x中的下标为3, 3, 1, 8的4个元素，组成一个新的数组
```


当使用布尔数组作为下标存取数组x中的元素时，将收集数组x中所有在布尔数组中对应下标为True的元素。使用布尔数组作为下标获得的数组不和原始数组共享数据空间，注意这种方式只对应于布尔数组，不能使用布尔列表。

np.argsort(x)与np.sort()



##  序列（字符串、列表、元组）、字典  $\rightarrow$ 索引切片操作异同、优缺点

## 控制语句：实现简单的程序功能

```python  
value1 if condition else value2
```


## 线性表

pop()
push()
remove()


## 随机数的生成

## 数值型的基本特征：均值方差

## 写程序对非数值型数据进行统计





# pandas数据结构



## Series

Series是一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。

```python
Series([4, 7,-5,3], index=['d','b','a','c'])

```


使用numpy进行运算会保留索引，在算数运算中会会自动对齐不同索引的数据。

利用isnull与notnull来检测缺失数据

Series对象本身及其索引都有一个name属性，可以通过赋值的方式就地修改

## DataFrame
DataFrame 生成基本的统计指标

**定义：** DataFrame是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。
可以视为Series的一个字典（共用一个索引，那么列名就是Series名吗？）。

横向：两个表的堆叠 concat axis = 1
纵向：

主键合并:merge

重叠合并:combine_first

指定了列序列，则DataFrame的列就会按照指定顺序排列!

通过类似字典标记的方式或属性的方式，可以将DataFrame的列获取为一个Series

为不存在的列赋值会创建出一个新列。关键字del用于删除列

嵌套字典来转换为DataFrame

切片或布尔型数组选取行

### 索引对象

pandas的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index

Index对象是不可修改的（immutable)

drop方法返回的是一个在指定轴上删除了指定值的新对象


当使用非整数作为切片索引时,其末端是包含的（inclusive)





# 异常数据的处理

## 异常数据的判断

常用的两种：物理方法和统计方法

### $3\sigma$准则

1. 计算均值$\bar x = \sum\limits_{i=1}^{n} x_i$
2. 计算标准差 $\sigma= \sqrt {{1 \over n-1} \sum \limits_{i=1}^n(x_i - \bar x)^2}$
3. 小于$\bar x -3 \sigma$或者大于$\bar x +3 \sigma$的为异常值

### 肖维勒准则

1. 计算数据的$\bar x  \text 与 \sigma$；
2. 计算每个数据的的误差$e_i = \vert x_i - x \vert $
3. 查概率积分表得到$\varepsilon = w_n \sigma$
4. 若$e_i > \varepsilon $则为误差值

### t检验
1. 将数据从小到大排列，计算排除min得到均值与方差。
2. 查表得k(n,$\alpha$)
3. 

### 格拉布斯准则
1. 将数据从小到大进行排序
2. 求出数据的$\bar x \text 与\sigma$
3. 查表得$\lambda(n,\alpha)$
4. 异常数据小于$\bar x - \lambda \sigma \text 大于 \bar x + \lambda \sigma$

### 狄克逊准则

1. 样本从大到小进行排序
2. 根据$n, \text 和\alpha$查找系数$D(n,\alpha)$，计算低端统计量$r^,$与高端统计量r
3. 统计量$r>r'$且$r > D(n,\alpha),x_{(n)}$为异常值 \
$r < r'$且$r > D(n,\alpha),x_{(1)}$为异常值

### 箱体图

异常值的范围为$(0,Q_1-1.5IQR) (Q_2+1.5IQR,+ \infty)$

## 异常数据的处理

### 删除

### 填充

### 插值

### 模型方法


# 神经网络

## 神经网络的分类
拓扑结构：单层、双层、多层 \
学习方式：感知机、认知机 \
连接方式： \
前馈-BP、卷积神经网络、径向神经网络、残差神经网络、循环神经网络
反馈-Hopfield网络、Elman网络、波尔兹曼机

## 欠拟合与过拟合的优化方法

---- 欠拟合 ----

**定义**：所建立模型不能很好地提取训练样本的特征，导致训练出来的模型拟合效果不好。

**产生原因**：模型复杂度过低或者特征量过少

**解决办法**：模型复杂化；增加表达能力更强的特征；调整参数和超参数

----- 过拟合 ----

**定义**：所建立的模型在训练样本中表现得过于优越，完美拟合可见数据，但在验证集与测试集中表现不佳。

**产生原因**：建模样本选取有误，如样本数量太少，选样方法错误，样本标签错误等，导致选取的样本数据无法代表总体；样本噪音干扰过大，使得模型将部分噪音认为是特征，从而导致模型畸变；假设的模型无法合理存在，或者说是假设成立的条件实际并不成立；参数太多，模型复杂度过高
 
**解决办法**：正则化、交叉验证、早停（early stopping）、数据集扩充、dropout




- 优缺点
- 应用场景差异
- 神经网络的流程
- 对于一个数据应用什么样的结构
  常用的损失函数
  优化方法及各自的优缺点
  

## 损失函数
### 定义
用来估计模型与预测值之间的差距的函数，常用L(y,f(x))来表示。

### 分类
0-1


### 优化方法


## 常见激活函数

### 激活函数的定义
引入非线性结构，使得神经网络能够逼近任何非线性函数

### 激活函数的性质


### 二值函数

### Sigmoid函数

### Relu函数

### Leaky ReLU


## 卷积神经网络

### 步骤
填充——卷积——池化三个步骤重复进
行，经过多次卷积，池化操作以后，将得到的特征图依
次按行展开, 连接成向量, 输入全连接网络
### 流程

a) 输入待卷积的图片（n\*n），以及确定卷积核的大小(f\*f)，一般来说，卷积
核的大小可以为指定输入图像尺寸的任意大小，且卷积核越大，则可提取
的输入特征值越复杂。
b) 确定步长 s 以及填充量 p，其中卷积核大小、步长以及填充共同决定了卷积层输出的特征图的尺寸大小(m\*m)。这里存在如下等量关系：m=(nf+2p)/s+1。
c) 填充：原因是当卷积核无法恰好滑动到原图的边缘时，导致边缘数据无法
提取，针对这个情况，我们在原始图形矩阵的周围补一圈全为 0 的数据，
这个称为填充。是否填充或填充几行，主要看卷积核是否能够达到原图边
缘而定。其中当填充大小为（f-1）/2 时得到的特征图像大小与原图大小
一致。假设图片大小为 5\*5，卷积核大小为 3\*3，步长为 1，则填充为 0
行，输出的特征图形大小为 3\*3
d) 卷积：首先将卷积核置于原始图形的最左上角，将对应元素相乘后加总，
将其放在特征图形的第一位，然后移动步长重复操作，直至卷积核达到填
充后图像的右下角，得到一个特征图像。其目的是将相邻像素之间的“轮
廓”过滤出来。
e) 池化：最常用的两中池化是最大池化和最小池化，其目的是降维。以最大
化池化为例，首先确定过滤器的大小和移动步长，将上面得到的特征图像
进行过滤，过滤准则是取被覆盖到区域的最大值
f) 单层的完整卷积步骤为：首先输入原始图像（如 5\*5），其次输入过滤器（如 3\*3），然后得到 1 个特征图像，利用激活函数（如 relu 函数）+偏值量，最后得到输出（3\*3\*1）

### 作用




# 预测模型

灰色模型的应用场景与步骤：

- 灰色模型的定义

灰色模型是利用离散随机数经过生成，变为较有规律的生成数，直接转化为微分方程的模型，对事物发展规律进行描述，常有GM（1,1）模型、 GM（1,N）模型、Verhulst模型、灰色波形预测模型。

### GM(1,1)模型

- 模型思想

GM(1,1)模型是基于随机的原始时间序列，经按时间累加后形成的新的时间序列。所呈现的规律用一阶线性微分方程的解来逼近的模型。

- 适用条件
  1. 数据量不少于4个；
  2. 原始数据非负、符合指数规律变化且变化不是很快。
- 建模过程
  1. 对给定原始观测时间序列$X^{(0)}$做一次累加生成$X^{(1)}$,做它的紧邻均值生成序列$Z^{(1)}$

  2. 定义灰导数、构造灰微分方程模型、灰色及百化微分方程系数的确定
     灰导数：$dX^{(1)}(k)=X^{(0)}(k)=X^{(1)}(k)-X^{(1)}(k-1)$
     灰微分方程模型:$d^{(1)}(k)+az^{(1)}(k) = b$，其中a为发展系数,b为灰作用量。
     GM(1,1)模型建模：用Y来表示$X^{(0)}$即dX^{(1)}(k)，用B来表示$\begin{pmatrix}  - z^{(2)} & 1\\  - z^{(3)}  & 1 \\  z^{(3)}  & 1\end{pmatrix}$ \,则公式为：$Y=BP$,参数的解为$P=(B^TB)^{-1}B^TY$
     白化微分方程:白化微分方程的解

  3. 数据还原及预测
- 应用场景

人口预测、反射性元素的衰变过程、化学反应中物质浓度的变化过程

### 灰色模型Verhulst

- 数据预处理
- 灰色verhulst微分方程
- 数据还原与预测

- 应用场景

- 模型拓展
  Logistic模型
  SI模型
  
### 灰色波形预测模型

- 建立模型

  k段折线图形：
  等高线
  𝜉等高时刻序列

- 模型预测步骤

# 数据清洗
数据清洗是对异常与错误数据的处理，所以不包括对异常数据的处理

# 数据质量评价方法

数据质量评估的时间
主要参考指标：
准确性
完整性
有效性检验：类型、格式、取值
时效性检测
