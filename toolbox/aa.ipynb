{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms,datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # 数据集路径\n",
    "    datas_root = '/home/xtu_conda/xtj2020/data/dogs-vs-cats/'\n",
    "    # 原始数据存放路径\n",
    "    origin_datas = '/home/xtu_conda/xtj2020/data/dogs-vs-cats/originData/'\n",
    "    # 训练集存放路径\n",
    "    train_datas ='/home/xtu_conda/xtj2020/data/dogs-vs-cats/trainData/'\n",
    "    # 验证集存放路径\n",
    "    valid_datas = '/home/xtu_conda/xtj2020/data/dogs-vs-cats/validData/'\n",
    "    # 测试集存放路径\n",
    "    test_datas = '/home/xtu_conda/xtj2020/data/dogs-vs-cats/testData/'\n",
    "    # 测试结果保存位置\n",
    "    result_files = '/home/xtu_conda/xtj2020/data/dogs-vs-cats/result.csv'\n",
    "\n",
    "    # 常用参数\n",
    "    # batch size\n",
    "    batch_size = 32\n",
    "    # mean and std\n",
    "    # 通过抽样计算得到图片的均值mean和标准差std\n",
    "    mean = [0.470, 0.431, 0.393]\n",
    "    std = [0.274, 0.263, 0.260]\n",
    "\n",
    "    # 预训练模型路径\n",
    "    path_vgg16 = './models/vgg16-397923af.pth'\n",
    "conf = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要从原始数据中筛选出猫狗数据\n",
    "origindata_files = os.listdir(os.path.join(conf.origin_datas,'train/'))\n",
    "# print(origindata_files)\n",
    "dogfiles = list(filter(lambda x : x[:3] == \"dog\",origindata_files))\n",
    "catfiles = list(filter(lambda x : x[:3] == \"cat\",origindata_files))\n",
    "dognums_train,catnums_train = len(dogfiles)*0.8,len(catfiles)*0.8\n",
    "for i in range(len(dogfiles)):\n",
    "    pre_path = os.path.join(conf.origin_datas,'train/',dogfiles[i])\n",
    "    if i < dognums_train:\n",
    "        new_path = os.path.join(conf.train_datas,'dog/')\n",
    "    else:\n",
    "        new_path = os.path.join(conf.valid_datas,'dog/')\n",
    "    shutil.move(pre_path,new_path)\n",
    "    \n",
    "for i in range(len(catfiles)):\n",
    "    pre_path = os.path.join(conf.origin_datas,'train/',catfiles[i])\n",
    "    if i < catnums_train:\n",
    "        new_path = os.path.join(conf.train_datas,'cat/')\n",
    "    else:\n",
    "        new_path = os.path.join(conf.valid_datas,'cat/')\n",
    "    shutil.move(pre_path,new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    通过该子类实现：\n",
    "    图像的预处理，加载数据集与验证集（含标签）\n",
    "    两个专用方法，获取数据与获取长度\n",
    "    '''\n",
    "    def __init__(self, train=True):\n",
    "        # 图片预处理\n",
    "        # Compose用于将多个transfrom组合起来\n",
    "        # ToTensor()将像素从[0, 255]转换为[0, 1.0]\n",
    "        # Normalize()用均值和标准差对图像标准化处理 x'=(x-mean)/std，加速收敛\n",
    "        self.transform = transforms.Compose([transforms.Resize((64, 64)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize(conf.mean, conf.std)])\n",
    "        self.train = train\n",
    "        # 加载训练数据集和验证数据集\n",
    "        if train:\n",
    "\n",
    "            # 数据加载\n",
    "            # 这里使用通用的ImageFolder和DataLoader数据加载器\n",
    "            # 数据类型 data_images = {'train': xxx, 'valid': xxx}\n",
    "            self.data_images = {x: datasets.ImageFolder(root=os.path.join(conf.datas_root, x),\n",
    "                                                        transform=self.transform)\n",
    "                                for x in ['trainData', 'validData']}\n",
    "            self.data_images_loader = {x: torch.utils.data.DataLoader(dataset=self.data_images[x],\n",
    "                                                                      batch_size=conf.batch_size,\n",
    "                                                                      shuffle=True)\n",
    "                                       for x in ['trainData', 'validData']}\n",
    "            # 图片分类 ['cat', 'dog']\n",
    "            self.classes = self.data_images['trainData'].classes\n",
    "            # 图片分类键值对 {'cat': 0, 'dog': 1}\n",
    "            self.classes_index = self.data_images['trainData'].class_to_idx\n",
    "\n",
    "        # 加载测试数据集\n",
    "        else:\n",
    "            images = [os.path.join(conf.data_test_root, img) for img in os.listdir(conf.data_test_root)]\n",
    "            self.images = sorted(images, key=lambda x: int(x.split('.')[-2].split('/')[-1]))\n",
    "\n",
    "    # 重载专有方法__getitem__\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images[index]\n",
    "        label = int(self.images[index].split('.')[-2].split('/')[-1])\n",
    "        data_images_test = Image.open(img_path)\n",
    "        data_images_test = self.transform(data_images_test)\n",
    "        return data_images_test, label\n",
    "\n",
    "    # 重载专有方法__len__\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需继承torch.nn.Module类\n",
    "class VGG16(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        # 定义卷积层和池化层，共13层卷积，5层池化\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # 简化版全连接层\n",
    "        self.classes = nn.Sequential(\n",
    "            nn.Linear(4 * 4 * 512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 2)\n",
    "        )\n",
    "\n",
    "        # VGG-16的全连接层\n",
    "        # self.classes = nn.Sequential(\n",
    "        #     nn.Linear(7 *7 *512, 4096),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=0.5),\n",
    "        #     nn.Linear(4096, 4096),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=0.5),\n",
    "        #     nn.Linear(4096, 2)\n",
    "        # )\n",
    "\n",
    "    # 定义每次执行的计算步骤\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 4 * 4* 512)\n",
    "        x = self.classes(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数是独立于数据迭代器的\n",
    "def get_mean_std(data_images):\n",
    "    '''\n",
    "    :param data_images: 加载好的数据集\n",
    "    :return: mean,std\n",
    "    '''\n",
    "    times, mean, std = 0, 0, 0\n",
    "    data_loader = {x: torch.utils.data.DataLoader(dataset=data_images[x],\n",
    "                                                  batch_size=1000,\n",
    "                                                  shuffle=True)\n",
    "                          for x in ['trainData', 'validData']}\n",
    "    for imgs, labels in data_loader['trainData']:\n",
    "        # imgs.shape = torch.Size([32, 3, 64, 64])\n",
    "        times += 1\n",
    "        mean += np.mean(imgs.numpy(), axis=(0, 2, 3))\n",
    "        std += np.std(imgs.numpy(), axis=(0, 2, 3))\n",
    "        print('times:', times)\n",
    "\n",
    "    mean /= times\n",
    "    std /= times\n",
    "    return mean, std\n",
    "\n",
    "dataset=Dataset()\n",
    "get_mean_std(dataset.data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 1\n",
      "times: 2\n",
      "times: 3\n",
      "times: 4\n",
      "times: 5\n",
      "times: 6\n",
      "times: 7\n",
      "times: 8\n",
      "times: 9\n",
      "times: 10\n",
      "times: 11\n",
      "times: 12\n",
      "times: 13\n",
      "times: 14\n",
      "times: 15\n",
      "times: 16\n",
      "times: 17\n",
      "times: 18\n",
      "times: 19\n",
      "times: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.06826375, 0.09302256, 0.09314134], dtype=float32),\n",
       " array([0.9203984, 0.93364  , 0.9546887], dtype=float32))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = {x:torch.utils.data.DataLoader(dataset = data_im)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64])\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dst = Dataset()\n",
    "# 预览其中一个批次的数据\n",
    "imgs, labels = iter(dst.data_images_loader['trainData']).next()\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-053acd96b15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_images' is not defined"
     ]
    }
   ],
   "source": [
    "classes_index = data_images['trainData'].class_to_idx\n",
    "print(classes_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-4fc6c5ea4e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 如果GPUs可用，则将模型上需要计算的所有参数复制到GPUs上\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/notebook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 定义优化器，优化模型上的所有参数和学习率，默认lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# 如果GPUs可用，则将模型上需要计算的所有参数复制到GPUs上\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "if torch.cuda.is_available():\n",
    "    X, y = X.cuda(), y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'datas_root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-b9086bfebe6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 数据类实例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 模型类实例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 配置类实例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-84a6186fa797>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# 这里使用通用的ImageFolder和DataLoader数据加载器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# 数据类型 data_images = {'train': xxx, 'valid': xxx}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             self.data_images = {x: datasets.ImageFolder(root=os.path.join(conf.datas_root, x),\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                         transform=self.transform)\n\u001b[1;32m     24\u001b[0m                                 for x in ['trainData', 'validData']}\n",
      "\u001b[0;32m<ipython-input-122-84a6186fa797>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# 这里使用通用的ImageFolder和DataLoader数据加载器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# 数据类型 data_images = {'train': xxx, 'valid': xxx}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             self.data_images = {x: datasets.ImageFolder(root=os.path.join(conf.datas_root, x),\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                         transform=self.transform)\n\u001b[1;32m     24\u001b[0m                                 for x in ['trainData', 'validData']}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Config' object has no attribute 'datas_root'"
     ]
    }
   ],
   "source": [
    "# 数据类实例\n",
    "dst = Dataset()\n",
    "# 模型类实例\n",
    "model = VGG16()\n",
    "# 配置类实例\n",
    "conf = Config()\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 定义优化器，优化模型上的所有参数和学习率，默认lr=1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 定义超级参数\n",
    "epoch_n = 10\n",
    "\n",
    "# 如果GPUs可用，则将模型上需要计算的所有参数复制到GPUs上\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# 代码执行时间装饰器\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kw):\n",
    "        begin = time.time()\n",
    "        # 执行函数体\n",
    "        func(*args, **kw)\n",
    "        end = time.time()\n",
    "\n",
    "        # 花费时间\n",
    "        cost = end - begin\n",
    "        print('本次一共花费时间：{:.2f}秒。'.format(cost))\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# 训练\n",
    "@timer\n",
    "def train():\n",
    "    for epoch in range(1, epoch_n + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, epoch_n))\n",
    "        print('-'*20)\n",
    "\n",
    "        for phase in ['trainData', 'validData']:\n",
    "            if phase == 'trainData':\n",
    "                print('Training...')\n",
    "                # 打开训练模式\n",
    "                model.train(True)\n",
    "            else:\n",
    "                print('Validing...')\n",
    "                # 关闭训练模式\n",
    "                model.train(False)\n",
    "\n",
    "            # 损失值\n",
    "            running_loss = 0.0\n",
    "            # 预测的正确数\n",
    "            running_correct = 0\n",
    "            # 让batch的值从1开始，便于后面计算\n",
    "            for batch, data in enumerate(dst.data_images_loader[phase], 1):\n",
    "                # 实际输入值和输出值\n",
    "                X, y = data\n",
    "                # 将参数复制到GPUs上进行运算\n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # outputs.shape = [32,2] -> [1,2]\n",
    "                outputs = model(X)\n",
    "                # 从输出结果中取出需要的预测值\n",
    "                # axis = 1 表示去按行取最大值\n",
    "                _, y_pred = torch.max(outputs.detach(), 1)\n",
    "                # 将累积的梯度置零\n",
    "                optimizer.zero_grad()\n",
    "                # 计算损失值\n",
    "                loss = loss_fn(outputs, y)\n",
    "                if phase == 'train':\n",
    "                    # 反向传播求导\n",
    "                    loss.backward()\n",
    "                    # 更新所有参数\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.detach().item()\n",
    "                running_correct += torch.sum(y_pred == y)\n",
    "\n",
    "                if batch % 500 == 0 and phase == 'train':\n",
    "                    print('Batch {}/{},Train Loss:{:.2f},Train Acc:{:.2f}%'.format(\n",
    "                        batch, len(dst.data_images[phase])/conf.batch_size, running_loss/batch, 100*running_correct.item()/(conf.batch_size*batch)\n",
    "                    ))\n",
    "            epoch_loss = running_loss*conf.batch_size/len(dst.data_images[phase])\n",
    "            epoch_acc = 100*running_correct.item()/len(dst.data_images[phase])\n",
    "            print('{} Loss:{:.2f} Acc:{:.2f}%'.format(phase, epoch_loss, epoch_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
